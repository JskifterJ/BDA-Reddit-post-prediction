{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-discharge",
   "metadata": {},
   "source": [
    "# **Washing Machine/Data Cleaning**\n",
    "1. ### Read Data\n",
    "2. ### Clean Data\n",
    "3. ### Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-sustainability",
   "metadata": {},
   "source": [
    "### **Reading block** *(do either 1. or 2.)* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-firewall",
   "metadata": {},
   "source": [
    "1. ##### Single score file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "postal-clinton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of subreddit (beware of capitalization): science\n",
      "Filename of dataset containing scores: science_set_scores\n"
     ]
    }
   ],
   "source": [
    "subreddit = input('Name of subreddit (beware of capitalization): ')\n",
    "scoreset = input('Filename of dataset containing scores: ')\n",
    "scoreset_csv = scoreset + '.csv'\n",
    "df = pd.read_csv(subreddit + '_dataset.csv')\n",
    "\n",
    "scores = pd.read_csv(scoreset_csv).rename(columns={'id':'post_ID'}) # Renaming id column to match original dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-mexican",
   "metadata": {},
   "source": [
    "2. ##### Multiple score files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smooth-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = input('Name of subreddit: ')\n",
    "df = pd.read_csv(subreddit + '_dataset.csv')\n",
    "\n",
    "score1 = pd.read_csv('dataset1 0-13334.csv').rename(columns={'id':'post_ID'}) # Renaming id column to match original dataset\n",
    "score2 = pd.read_csv('dataset2 13334-26667.csv').rename(columns={'id':'post_ID'})\n",
    "score3 = pd.read_csv('dataset3 26667-40100.csv').rename(columns={'id':'post_ID'})\n",
    "scores = pd.concat([score1, score2, score3]) # Combining all score df's into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-double",
   "metadata": {},
   "source": [
    "### **Cleaning block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "responsible-intent",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-c509463f8ba7>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['title length'][x] = len(df['title'].iloc[x])\n",
      "C:\\Users\\wisev\\.conda\\envs\\BDA\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(df, scores, how='left', on='post_ID') #adding scraped scores to original dataset\n",
    "df.drop('score_x', axis=1, inplace=True) #Removing old score column\n",
    "df = df.rename(columns={'score_y':'score'}).dropna(subset=['score']) # Renaming score column & dropping rows where score == NaN\n",
    "df.score = df.score.replace(r'[k]+$', '00', regex=True) # Reformatting score values from e.g. '19.2k' to '19.200'\n",
    "df.score = df.score.replace(r'\\.', '', regex=True).astype(int) # Reformatting score values from e.g. '19.200' to '19200' and changing datatype to 'int64'\n",
    "\n",
    "df['title length'] = 0 #Generating title length column to dataset filled with 0s\n",
    "df['time_hr'] = pd.DataFrame([x[11:] for x in df['timestamp']]) #Generating new column with only hours\n",
    "df['24h_posttime'] = [0 for x in range(len(df))] #Generating new column filled with 0s\n",
    "\n",
    "for x in range(len(df.title)): #Generating title length & 24hr_post_time columns\n",
    "    df['title length'][x] = len(df['title'].iloc[x])\n",
    "    for y in range(24):\n",
    "        if int(df.time_hr.iloc[x][1]) == y:\n",
    "            df['24h_posttime'].iloc[x] = y\n",
    "\n",
    "df.drop('time_hr', axis=1, inplace=True) #Removing old timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-coupon",
   "metadata": {},
   "source": [
    "### **Saving block** *(change filename)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "checked-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datasets\\\\' + subreddit + '_dataset_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
